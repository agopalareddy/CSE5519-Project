"""
Defense Validation Framework
Author: Aadarsha Gopala Reddy

This module executes and validates defense scripts generated by the blue team.
It tests detection scripts against both malicious and benign images.
"""

import importlib.util
import sys
from pathlib import Path
from typing import List, Dict, Any


class DefenseValidator:
    """Validates defense scripts against test images."""

    def __init__(self):
        self.results = []

    def load_defense_script(self, script_path: str):
        """
        Dynamically load a Python defense script.

        Args:
            script_path: Path to the defense script

        Returns:
            Loaded module containing detect_attack function
        """
        spec = importlib.util.spec_from_file_location("defense_module", script_path)
        module = importlib.util.module_from_spec(spec)
        sys.modules["defense_module"] = module
        spec.loader.exec_module(module)

        if not hasattr(module, "detect_attack"):
            raise ValueError("Defense script must have a 'detect_attack' function")

        return module

    def validate_defense(
        self,
        defense_script_path: str,
        malicious_images: List[str],
        benign_images: List[str],
    ) -> Dict[str, Any]:
        """
        Test a defense script against malicious and benign images.

        Args:
            defense_script_path: Path to the Python defense script
            malicious_images: List of paths to attack images (should be detected)
            benign_images: List of paths to safe images (should NOT be detected)

        Returns:
            Dictionary with precision, recall, accuracy, and detailed results
        """
        try:
            defense_module = self.load_defense_script(defense_script_path)
        except Exception as e:
            return {
                "error": f"Failed to load defense script: {str(e)}",
                "precision": 0.0,
                "recall": 0.0,
                "accuracy": 0.0,
            }

        true_positives = 0  # Correctly detected attacks
        false_positives = 0  # Benign flagged as attack
        true_negatives = 0  # Correctly allowed benign
        false_negatives = 0  # Missed attacks

        # Test against malicious images
        for img_path in malicious_images:
            try:
                is_attack = defense_module.detect_attack(img_path)
                if is_attack:
                    true_positives += 1
                else:
                    false_negatives += 1
            except Exception as e:
                print(f"Error testing {img_path}: {e}")
                false_negatives += 1

        # Test against benign images
        for img_path in benign_images:
            try:
                is_attack = defense_module.detect_attack(img_path)
                if is_attack:
                    false_positives += 1
                else:
                    true_negatives += 1
            except Exception as e:
                print(f"Error testing {img_path}: {e}")
                false_positives += 1

        # Calculate metrics
        total = len(malicious_images) + len(benign_images)
        precision = (
            true_positives / (true_positives + false_positives)
            if (true_positives + false_positives) > 0
            else 0
        )
        recall = (
            true_positives / (true_positives + false_negatives)
            if (true_positives + false_negatives) > 0
            else 0
        )
        accuracy = (true_positives + true_negatives) / total if total > 0 else 0

        return {
            "precision": precision,
            "recall": recall,
            "accuracy": accuracy,
            "true_positives": true_positives,
            "false_positives": false_positives,
            "true_negatives": true_negatives,
            "false_negatives": false_negatives,
            "total_malicious": len(malicious_images),
            "total_benign": len(benign_images),
        }

    def print_results(self, results: Dict[str, Any]):
        """Pretty print validation results."""
        print("\n=== Defense Validation Results ===")
        if "error" in results:
            print(f"ERROR: {results['error']}")
            return

        print(f"Accuracy:  {results['accuracy']:.2%}")
        print(f"Precision: {results['precision']:.2%}")
        print(f"Recall:    {results['recall']:.2%}")
        print(f"\nConfusion Matrix:")
        print(
            f"  True Positives:  {results['true_positives']} / {results['total_malicious']}"
        )
        print(
            f"  False Negatives: {results['false_negatives']} / {results['total_malicious']}"
        )
        print(
            f"  True Negatives:  {results['true_negatives']} / {results['total_benign']}"
        )
        print(
            f"  False Positives: {results['false_positives']} / {results['total_benign']}"
        )


if __name__ == "__main__":
    # Example usage
    validator = DefenseValidator()

    # TODO: Replace with actual image paths
    # malicious = ["attack1.png", "attack2.png"]
    # benign = ["safe1.png", "safe2.png"]
    # results = validator.validate_defense("example_defense.py", malicious, benign)
    # validator.print_results(results)

    print(
        "Defense Validator initialized. Use validate_defense() method with actual images."
    )
